{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#import libraries from sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "##### new import try\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model : SVC(C=100, gamma=0.0001, probability=True)\n",
      "model fit time:  SVC(C=100, gamma=0.0001, probability=True)  :  16.95537567138672\n",
      "model name:  ['svm']\n",
      "Accuracy:  \n",
      " 98.83040935672514\n",
      "base model : KNeighborsClassifier()\n",
      "model fit time:  KNeighborsClassifier()  :  1.9915103912353516\n",
      "model name:  ['svm', 'knn']\n",
      "Accuracy:  \n",
      " 95.90643274853801\n",
      "base model : DecisionTreeClassifier()\n",
      "model fit time:  DecisionTreeClassifier()  :  4.985332489013672\n",
      "model name:  ['svm', 'knn', 'cart']\n",
      "Accuracy:  \n",
      " 91.22807017543859\n",
      "base model : RandomForestClassifier()\n",
      "model fit time:  RandomForestClassifier()  :  221.4510440826416\n",
      "model name:  ['svm', 'knn', 'cart', 'rf']\n",
      "Accuracy:  \n",
      " 97.07602339181285\n",
      "base model : GaussianNB()\n",
      "model fit time:  GaussianNB()  :  0.9949207305908203\n",
      "model name:  ['svm', 'knn', 'cart', 'rf', 'bays']\n",
      "Accuracy:  \n",
      " 93.56725146198829\n",
      "base model : StackingClassifier(cv=7,\n",
      "                   estimators=[('svm',\n",
      "                                SVC(C=100, gamma=0.0001, probability=True)),\n",
      "                               ('knn', KNeighborsClassifier()),\n",
      "                               ('cart', DecisionTreeClassifier())],\n",
      "                   final_estimator=StackingClassifier(cv=7,\n",
      "                                                      estimators=[('rf',\n",
      "                                                                   RandomForestClassifier()),\n",
      "                                                                  ('bays',\n",
      "                                                                   GaussianNB())],\n",
      "                                                      final_estimator=LogisticRegression(),\n",
      "                                                      passthrough=True),\n",
      "                   passthrough=True)\n"
     ]
    }
   ],
   "source": [
    " # load dataset\n",
    " df = pd.read_csv(\"breast_cancer_data.csv\")\n",
    " df = df.drop(['id','Unnamed: 32'], axis =1)\n",
    "  \n",
    " diag_map = {'M':1, 'B':0}\n",
    " df['diagnosis'] = df['diagnosis'].map(diag_map)  \n",
    " \n",
    "# get data\n",
    "def get_dataset():\n",
    "    # set X,y\n",
    "    y = df['diagnosis']\n",
    "    X = df.drop(['diagnosis'], axis = 1)\n",
    "    \n",
    "    # Scaler dataset without target\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# define PCA\n",
    "def pca_component(X):\n",
    "    \n",
    "    pca_breast = PCA(n_components=8)\n",
    "    pca_breast.fit(X)\n",
    "    pca_breastX = pca_breast.fit_transform(X)\n",
    "   \n",
    "    final_data = pca_breastX\n",
    "    return final_data\n",
    "\n",
    "#feature scaling\n",
    "def get_scaler(X, y):\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    y = sc.transform(y)\n",
    "   # print(\"after normalization: \",X_train.head())\n",
    "    return X, y\n",
    "\n",
    "# get models\n",
    "def get_basemodels():\n",
    "    \n",
    "    models= dict()\n",
    "    #level 1 models\n",
    "    \n",
    "    models['svm'] = SVC(kernel='rbf', C=100, gamma=0.0001, probability=True)\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['cart'] = DecisionTreeClassifier() \n",
    "    models['rf'] = RandomForestClassifier()\n",
    "    models['bays'] = GaussianNB()\n",
    "       \n",
    "    #level stacking\n",
    "    models['stacking_one'] = get_stacking()\n",
    "    #models['stacking_two'] = get_stacking_two()\n",
    "   \n",
    "    return models\n",
    "\n",
    "# get a stacking ensemble of models first time\n",
    "def get_stacking():\n",
    "\n",
    "    level0 = list()\n",
    "    level0.append(('svm', SVC(kernel='rbf', C=100, gamma=0.0001,probability=True) ) )\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "   \n",
    "    level1 = get_stacking_two()\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=7, passthrough=True)\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "# get a stacking ensemble of models second time\n",
    "def get_stacking_two():\n",
    "\n",
    "    level2 = list()\n",
    "   \n",
    "    level2.append(('rf' , RandomForestClassifier()))\n",
    "    level2.append(('bays', GaussianNB()))   \n",
    "   \n",
    "    level3 = LogisticRegression(penalty='l2')\n",
    "   \n",
    "    model = StackingClassifier(estimators=level2, final_estimator=level3, cv=7, passthrough=True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# draw confusion matrix\n",
    " def plot_confusion_matrix(y_predict):\n",
    "        \n",
    "    con_matrix = confusion_matrix(Y_test, y_predict, labels=[0, 1])\n",
    " \n",
    "    df_cm = pd.DataFrame(con_matrix, index = [i for i in [\"0\",\"1\"]],\n",
    "                         columns = [i for i in [\"Predict benign\",\"Predict Malignant\"]])\n",
    "   \n",
    "    pyplot.title(eva_model)\n",
    "    pyplot.figure(figsize = (8,6))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(eva_model, X, y):\n",
    "       \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(eva_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #fit model\n",
    "    model_fit = eva_model.fit(X,y)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    y_predict = model_fit.predict(X_test)\n",
    "    print(\"model fit time: \",eva_model,\" : \", fit_time*1000)\n",
    "   \n",
    "    return scores, y_predict\n",
    "\n",
    "#Calling function\n",
    "# define dataset\n",
    "X_train, X_test, Y_train, Y_test = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_basemodels()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, eva_model in models.items():\n",
    "    print(\"base model :\", eva_model)\n",
    "    scores, y_predict = evaluate_model(eva_model, X_train, Y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    print('model name: ',names)\n",
    "    \n",
    "    print('Accuracy:  \\n ' + str(accuracy_score(Y_test, y_predict)*100) )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
